---
title: "Meta Analysis of User Collections & Models"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 2
        number_sections: true
---
```{r load and set packages, echo=F, warning=F, message=F,  results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      error = F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

# flextable settings
library(flextable)
set_flextable_defaults(theme_fun = theme_alafoli,
                       font.color = "grey10",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

options(knitr.duplicate.label = "allow")

options(scipen=999)

# source
source(here::here("scripts/load_packages.R"))
source(here::here("functions/theme_phil.R"))
rm(a)

# functions
source(here::here("functions/get_collection.R"))

# library
#library(webshot2)
library(magick)
library(bggAnalytics)
library(tidymodels)
library(workflows)
library(rsample)

set_flextable_defaults(theme_fun = theme_booktabs,
                       font.color = "black",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

```{r get big query tables, warning=F, message=F, results = 'hide'}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query active games
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

# query active games
game_expansions<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.game_expansions')

# create caption for plots
my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))


# bgg_rankings<-bq_table_query(bq_bgg,
#                         query = 
#                         quiet = F)

# # set project and schema
# bq_bgg<- bq_dataset(project = PROJECT_ID,
#                                     dataset = 'bgg')

```

# Context {-}

I recently made a post in which I offered to train predictive models for user BoardGameGeek collections on r/boardgames. This amounted to training classification models for games that users own or have rated, training on games published before 2020 for must users and predicting games published from 2020 onwards. 

Link to post:
subbhttps://www.reddit.com/r/boardgames/comments/rtmq3o/post_your_bgg_username_and_ill_train_a_predictive/

This notebook is an analysis of the users who participated and what the models learned about the.

It is worth noting here that this is *not* a representative sample of either BGG or r/boardgames. Users selected into the sample based on viewing the reddit post over the weekend, which was January 1st, so if this sample represents any population it is the bored-at-home-and-checking-the-boardgame-subreddit-on-saturday-morning crowd. Nonetheless, we can still look at the data for these users and maybe make some cool visualizations.

# User Collections

I'll start by getting the full list of users for whom I have trained models - this includes some users from previous reddit posts, friends of mine, and some prominent reviewers.

```{r get user names from folder}

# get user list
users = list.files(here::here("predict_user_collections/user_reports")) %>%
        as_tibble() %>%
        filter(!grepl("(files)$", value)) %>% # filter out those that models didn't run for, which were ones with just the files
        rename(file = value) %>%
        mutate(user = gsub('.{10}$', '', file)) %>%
        mutate(year = str_sub(gsub(".html", "", file), -4, -1)) %>%
        mutate(user = case_when(user == 'The_Inquiry' ~ '_The_Inquiry_',
                                TRUE ~ user))

# how many analyses have i run?
n_users = users %>%
        mutate(date = Sys.Date()) %>%
        group_by(date) %>%
        summarize(users_analyzed = n_distinct(user))

n_users

```

As of `r n_users$date`, I have run analyses for `r n_users$users_analyzed` collections.

We'll now pull data for each of these collections into one large table.

```{r pull collections, warning=F, message=F, result='hide'}

# library(doParallel)
# library(parallel)
# 
# # get list of unique users
# get_users = unique(users$user)
# 
# registerDoParallel(detectCores()-1)
# 
# # loop in parallel
# user_collections = foreach(i = 1:length(get_users), 
#                            .packages = c('tidyverse',
#                                          'bggAnalytics'),
#                            .errorhandling = 'pass') %dopar% {
#                 
#                 foo = get_collection(get_users[i]) %>%
#                         nest(-username)
#                 
#                 foo
#                            }
# 
# # bind together
# user_collections_tbl= rbindlist(user_collections) %>% as_tibble()
# 
# # which names did we miss (due to whitespace?)
# missing_users = gsub("_",
#                      "%20",
#                      get_users[which(!(get_users %in% user_collections_tbl$username))])
# 
# #@ get these guys
# missing_users_collections = foreach(i = 1:length(missing_users), 
#                            .packages = c('tidyverse',
#                                          'bggAnalytics'),
#                            .errorhandling = 'pass') %dopar% {
#                 
#                 foo = get_collection(missing_users[i]) %>%
#                         nest(-username)
#                 
#                 foo
#                            }
# 
# # get into a tbl
# missing_users_collections_tbl = rbindlist(missing_users_collections) %>% as_tibble()
# 
# # bind together and get them together
# collections_table = bind_rows(user_collections_tbl,
#                               missing_users_collections_tbl)
# 
# # stop parallel
# registerDoSEQ()
# 
# # remove 
# rm(missing_users_collections,
#    missing_users_collections_tbl,
#    user_collections,
#    user_collections_tbl)

# # save locally
# readr::write_rds(collections_table,
#                                   file = here::here("predict_user_collections/meta-analysis/files", paste("collections_table_", Sys.Date(), ".Rdata", sep="")))

# load most recent
collections_files = list.files(here::here("predict_user_collections/meta-analysis/files"))
most_recent_table = collections_files[grepl("table", collections_files)]
most_recent_full_game_ids = collections_files[grepl("full_game_ids", collections_files)]
collections_table = readr::read_rds(here::here("predict_user_collections/meta-analysis/files", most_recent_table))
full_game_ids= readr::read_rds(here::here("predict_user_collections/meta-analysis/files", most_recent_full_game_ids))

```

We now have a table of all of these user's collections. We now need to get information from BGG about games, which we can use in our analysis. I'll also grab info on game expansions, as I'll want to omit those from a lot of this analysis

```{r get game info}

source(here::here("functions/get_bgg_data_from_github.R"))
source(here::here("functions/get_game_record.R"))

# get todays data from bgg
bgg_today<-get_bgg_data_from_github(Sys.Date())

# # get flattened file for these games _and any games that users might have that are not present here_
# bgg_game_ids = bgg_today %>%
#         select(game_id) %>%
#         pull(game_id) %>%
#         unique() 
# 
# # now we'll see if there are games users own, have rated, or have previously owned that aren't in the bgg data
# collection_game_ids = collections_table %>%
#         unnest(data) %>%
#         filter(!(game_id %in% unique(game_expansions$expansion_id))) %>%
#         pull(game_id) %>%
#         unique()
# 
# # how many games do people have that aren't in the bgg table?
# missing_game_ids = collection_game_ids[which(!(collection_game_ids %in% bgg_game_ids))]
# 
# # combine
# full_game_ids = c(bgg_game_ids,
#                   missing_game_ids)
# 
# # save game_ids
# readr::write_rds(full_game_ids, 
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("full_game_ids_", Sys.Date(), ".Rdata", sep="")))

# # split into model
# info = games_flattened %>%
#         select(timestamp,
#                type,
#                game_id,
#                type,
#                name,
#                yearpublished,
#                rank,
#                average,
#                baverage,
#                stddev,
#                usersrated,
#                avgweight,
#                minplayers,
#                maxplayers,
#                playingtime,
#                minplaytime,
#                maxplaytime,
#                minage,
#                numtrading,
#                numwanting,
#                numwishing,
#                numcomments)
# 
# categories = games_flattened %>%
#         select(game_id,
#                starts_with("cat")) %>%
#         melt(id.vars = c("game_id")) %>%
#         mutate(variable = gsub("^(cat_)", "", variable)) %>%
#         filter(value == 1) %>%
#         rename(category = variable)

```

We'll then get a full set of data on games from the daily BGG table as well as games that are in user collections.

```{r push all ids through API}

# use function to get records from bgg
# # takes about, 10 min?
# suppressMessages({
#         games_flattened = get_game_record(full_game_ids) %>%
#                 mutate(number_designers = rowSums(across(starts_with("des_"))))
# })

# # save both
# readr::write_rds(games_flattened,
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("games_flattened_", Sys.Date(), ".Rdata", sep="")))

# load from local
most_recent_flattened = collections_files[grepl("games_flattened", collections_files)]
games_flattened = readr::read_rds(here::here("predict_user_collections/meta-analysis/files",
                                             most_recent_flattened))

# readr::write_rds(flattened_names, 
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("flattened_names_", Sys.Date(), ".Rdata", sep="")))

# # unite to one string varaible for storage
# games_united = games_flattened %>%
#         unite(string, sep = "_", remove = TRUE, na.rm = FALSE)
# 
# # get column names
# flattened_names = names(games_flattened)

# # get column names
# flattened_names = names(games_flattened)
# # separated
# games_separated = games_united %>%
#         separate(string, 
#                  into = flattened_names,
#                  convert = T,
#                  sep = "_",
#                  remove = T)

```

We can then join this up with our collection data as needed so we can get some basic features about games.

```{r combine}

collections_info = collections_table %>%
        unnest(data) %>%
        filter(game_id %in% full_game_ids) %>%
        left_join(., games_flattened %>%
                          select(timestamp,
                                 game_id,
                                 name,
                                 yearpublished,
                                 rank,
                                 average,
                                 baverage,
                                 stddev,
                                 usersrated,
                                 avgweight,
                                 minplayers,
                                 maxplayers,
                                 timestamp),
                  by = c("game_id"))

```

# Exploratory Analysis

Let's look at a couple of different pieces about a collection. How many games do they own - meaning games that are marked as currently in their collection. How games have they rated - meaning they have assigned a rating to a game. How many games have they marked as previously owned?

```{r plot owned, wanted, etc}

#dists_collection = 
collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        group_by(variable) %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games)) %>%
        ggplot(., aes(x=games,
                      y=reorder(variable, median_games)))+
        # geom_density_ridges(alpha=0.8,
        #                     rel_min_height = 0.01, 
        #                     jittered_points = TRUE,
        #                     position = position_points_jitter(width = 0.1, height = 0),
        #                     point_shape = "|", point_size = 2)+
        stat_density_ridges(alpha=0.8,
                            stat = 'binline',
                            quantile_lines = TRUE,
                            quantile_fun = median,
                            quantiles = 2,
                            draw_baseline = F) +
        theme_phil()+
        xlab("number of games")+
        ylab("collection")+
        my_caption
        
```

For each of these outcomes, we have some collections that are way out in the tails of extremely right-skewed distributions. I want to dig into this a bit more. I'm going to create a new category, owned, that marks a user as having owned a game if it is currently in their collection or if they've previously 

What was the distribution of games owned by the users (not counting expansions)?

```{r plot owned distribution}

temp = collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        filter(variable == 'owned') %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games))

temp %>%
        ggplot(., aes(x=games))+
      #  geom_density(alpha=0.8)+
        geom_histogram(bins=100,
                       fill = 'grey60')+
        geom_vline(aes(xintercept = mean_games))+
        facet_wrap(variable~.,
                   ncol =1)+
        theme_phil()+
        annotate("text",
                 x = temp$median_games[1]*5,
                 y = 50,
                 label = paste('median games owned:', temp$median_games[1]))+
        xlab("number of games owned")+
        ylab("number of users")+
        annotate("text",
                 x = 0.9*temp$max_games[1],
                 y = 19,
                 label = paste('most games owned:', temp$max_games[1]))+
        geom_curve(
                aes(x = 0.9*max_games, 
                    y = 15,
                    xend = max_games, 
                    yend = 5),
                data = temp,
                curvature = -0.2,
                arrow = arrow(length = unit(0.03, "npc")))+
        my_caption

median_games_owned = temp$mean_games[1]

rm(temp)

```

What about the distribution of games rated?

```{r plot owned}

temp = collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        filter(variable == 'rated') %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games))

temp %>%
        ggplot(., aes(x=games))+
      #  geom_density(alpha=0.8)+
        geom_histogram(bins=100,
                       fill = 'grey60')+
        geom_vline(aes(xintercept = mean_games))+
        facet_wrap(variable~.,
                   ncol =1)+
        theme_phil()+
        annotate("text",
                 x = temp$median_games[1]*5,
                 y = 50,
                 label = paste('median games rated:', temp$median_games[1]))+
        xlab("number of games rated")+
        ylab("number of users")+
        annotate("text",
                 x = 0.9*temp$max_games[1],
                 y = 19,
                 label = paste('most games rated:', temp$max_games[1]))+
        geom_curve(
                aes(x = 0.9*max_games, 
                    y = 15,
                    xend = max_games, 
                    yend = 5),
                data = temp,
                curvature = -0.2,
                arrow = arrow(length = unit(0.03, "npc")))+
        my_caption

median_games_rated = temp$median_games[1]
rm(temp)

```

The median for games rated (`r median_games_rated`) is a bit lower than the median for games owned (`r median_games_owned`). Do users usually rate more games than they own, or vice versa? We can plot the each user's number of games owned vs number of games rated to get an idea.

```{r owned vs rated}

collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        spread(variable, games) %>%
        filter(rated > 0) %>%
        mutate(diff = owned - rated) %>%
        mutate(type = case_when(diff >= 0 ~ 'owned more than rated',
                                diff <=0 ~ 'rated more than owned',
                                diff == 0 ~ 'same')) %>%
        group_by(type) %>%
        count() %>%
        ungroup() %>%
        mutate(prop = round(prop.table(n),2)) %>%
        flextable() %>%
        flextable::autofit() %>%
        color(part = "body",
              color = "white") %>%
        bg(., i = ~ type == 'owned more than rated',
           bg = 'blue') %>%
        bg(., i = ~ type == 'rated more than owned',
           bg = 'darkorange')

collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        spread(variable, games) %>%
        filter(rated > 0) %>%
        mutate(diff = owned - rated) %>%
        ggplot(., aes(x=owned,
                      color = diff,
                      label = username,
                      y=rated))+
        geom_point(alpha=0.75)+
        # geom_text_repel(check_overlap = T,
        #           size = 3)+
        theme_phil()+
        geom_abline(intercept = 0,
                    slope = 1,
                    linetype = 'dotted')+
        annotate("label",
                 x = 200,
                 y = 1200,
                 color = 'darkorange',
                 label = "rated more than owned")+
        annotate("label",
                 x = 1000,
                 y = 150,
                 color = 'blue',
                 label = "owned more than rated")+
        my_caption+
        scale_color_gradient(low = "darkorange",
                             high = "blue",
                             limits = c(-100, 100),
                             oob = scales::squish)+
        guides(color = "none")+
        xlab("number of games owned")+
        ylab("number of games rated")



# collections_info %>%
#         filter(type == 'boardgame') %>%
#         select(username, date, game_id, rating, own, prevowned) %>%
#         mutate(rated = case_when(is.na(rating) ~ 0,
#                                  TRUE ~ 1)) %>%
#         select(-rating) %>%
#         melt(id.vars = c("username", "date", "game_id")) %>%
#         group_by(username, date, variable) %>%
#         summarize(games = sum(value),
#                   .groups = 'drop') %>%
#         spread(variable, games) %>%
#         filter(rated > 0) %>%
#         mutate(diff = own - rated) %>%
#         ggplot(., aes(x=diff))+
#         geom_density(fill = 'gray60',
#                      color = 'grey60',
#                      alpha = 0.9)+
#       #  geom_histogram(bins = 100)+
#         theme_phil()+
#         xlab("Games Owned - Games Rated")
        
```

The majority of users have owned more than they've rated, which holds even if we filter out users that don't rate their games. I wonder how much of this is from people buying newer games during the pandemic and not yet being able to get them to the table? This is the case for me and my collection, at any rate.


```{r plot owned vs rated over time}


collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, yearpublished, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "yearpublished", "game_id")) %>%
        filter(yearpublished > 1980) %>%
        group_by(date, yearpublished, variable) %>%
        summarize(n_games = sum(value),
                  .groups = 'drop') %>%
        filter(variable == 'owned' | variable == 'rated') %>%
        ggplot(., aes(x= yearpublished,
                      color = variable,
                      y = n_games))+
        geom_line(lwd=1.03)+
        scale_color_manual(values = c("darkorange",
                                      "blue"))+
        theme_phil()+
        my_caption

```

Certainly looks like people aren't getting newer games to the table in order to rate them. Whether the pandemic is the source of that, we can't be sure.

## Ratings

How do the users compare in their ratings to the average ratings on BoardGameGeek? Let's look at the top 50 games with the highest ratings in people's collections. To make this fancy, we'll plot the distribution of votes.

```{r top ratings, fig.height=15, fig.width=8}

set.seed(1999)
samp_ratings = collections_info %>%
        filter(!(is.na(rating))) %>%
        filter(type == 'boardgame') %>% 
        group_by(game_id) %>%
        mutate(sample_mean = mean(rating),
               sample_median = median(rating),
               sd_ratings = sd(rating),
               sample_ratings = n()) %>%
        filter(sample_ratings > 14) %>%
        ungroup() %>%
        arrange(desc(sample_mean)) 

sum_ratings= collections_info %>%
        filter(!(is.na(rating))) %>%
        filter(type == 'boardgame') %>% 
        group_by(game_id, name) %>%
        summarize(sample_mean = mean(rating),
                  sd_ratings = sd(rating),
                  sample_median = median(rating),
                  sample_ratings = n(),
                  .groups = 'drop') %>%
        filter(sample_ratings > 9) %>%
        arrange(desc(sample_mean))
        
# top 
samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                       head(100) %>%
                       pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sample_mean),
                      fill = stat(x),
                      x=rating))+
        geom_density_ridges_gradient(alpha = 0.8,
                                     quantile_lines = T,
                                     quantile_fun = mean,
                                     color = 'white')+
        scale_fill_gradient2_tableau(limits = c(5, 8),
                                      oob = scales::squish)+
        guides(fill = guide_colorbar(barwidth = 10,
                                     barheight = 0.5,
                                     title = 'rating',
                                     title.position = 'top'))+
        # stat_density_ridges(alpha=0.8,
        #                     color = 'white',
        #                     quantile_lines = TRUE,
        #                     quantile_fun = mean,
        #                     quantiles = 2)+
        theme_phil()+
        theme(legend.title = element_text())+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))+
        theme(axis.text.y = element_text(size=12))+
        my_caption+
        ylab("")+
        ggtitle("Which Games are the Highest Rated?",
                subtitle = str_wrap("Displaying distributions of ratings for games with highest ratings in sample of user collections. Filtering to games with at least 15 ratings.", 125))

```

Now let's look at the lowest games rated.

```{r lowest ratings, fig.height=15, fig.width=8}

# bottom
samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                       tail(100) %>%
                       pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sample_mean),
                      fill = stat(x),
                      x=rating))+
        geom_density_ridges_gradient(alpha = 0.8,
                                     quantile_lines = T,
                                     quantile_fun = mean,
                                     color = 'white')+
        scale_fill_gradient2_tableau(limits = c(5, 8),
                                      oob = scales::squish)+
        guides(fill = guide_colorbar(barwidth = 10,
                                     barheight = 0.5,
                                     title = 'rating',
                                     title.position = 'top'))+
        # stat_density_ridges(alpha=0.8,
        #                     color = 'white',
        #                     quantile_lines = TRUE,
        #                     quantile_fun = mean,
        #                     quantiles = 2)+
        theme_phil()+
        theme(legend.title = element_text())+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))+
        theme(axis.text.y = element_text(size=12))+
        my_caption+
        ylab("")+
        ggtitle("Which Games are the Lowest Rated?",
                subtitle = str_wrap("Displaying distributions of ratings for games with lowest ratings in sample of user collections. Filtering to games with at least 15 ratings.", 125))

```

Most polarizing

```{r lowest rated, fig.height=15, fig.width=10}

samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                                     arrange(desc(sd_ratings)) %>%
                                     head(100) %>%
                                     pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sample_mean),
                      fill = stat(x),
                      x=rating))+
        geom_density_ridges_gradient(alpha = 0.8,
                                     quantile_lines = T,
                                     quantile_fun = mean,
                                     color = 'white')+
        scale_fill_gradient2_tableau(limits = c(5, 8),
                                      oob = scales::squish)+
        guides(fill = guide_colorbar(barwidth = 10,
                                     barheight = 0.5,
                                     title = 'rating',
                                     title.position = 'top'))+
        # stat_density_ridges(alpha=0.8,
        #                     color = 'white',
        #                     quantile_lines = TRUE,
        #                     quantile_fun = mean,
        #                     quantiles = 2)+
        theme_phil()+
        theme(legend.title = element_text())+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))+
        theme(axis.text.y = element_text(size=12))+
        my_caption+
        ylab("")+
        ggtitle("Which Games are the Most Polarizing?",
                subtitle = str_wrap("Displaying distributions of ratings for games with highest variance in sample of user collections. Filtering to games with at least 15 ratings.", 125))


```

Games most freqently owned and rated.

```{r games owned, fig.height=8, fig.width=10, warning=F, message=F}

collections_info %>%
        filter(type == 'boardgame') %>%
        filter(!(is.na(yearpublished))) %>%
        select(username, yearpublished, date, game_id, name, rating, own, prevowned) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "name", "yearpublished", "game_id")) %>%
        filter(variable == 'owned' | variable == 'rated') %>%
        group_by(game_id, yearpublished, variable, name) %>%
        summarize(n = sum(value),
                  .groups = 'drop') %>%
        ungroup() %>%
        pivot_wider(., id_cols = c("name", "yearpublished", "game_id"),
                    names_from = c("variable"),
                    values_from = c("n")) %>%
        select(yearpublished, game_id, name, everything()) %>%
        mutate(diff = owned - rated) %>%
        arrange(desc(diff)) %>%
        mutate_at(c("yearpublished", "game_id"),
                       ~ as.character(.)) %>%
        DT::datatable()

```

# Models

I previously trained models for each user, but owing to storage I didn't save each user's model. We can just retrain here. This will require us to pull in functions for creating recipes and models at the user level.

```{r get data ready for modeling}

# Load previously queried training and test data from the local layer.
games_datasets = readr::read_rds(here::here("active", "games_datasets.Rdata"))

most_recent_date = as.Date(games_datasets$train$timestamp[1])

my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", most_recent_date),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))

# collections_info %>%
#         filter(type == 'boardgame') %>%
#         select(username, date, yearpublished, game_id, rating, own, prevowned) %>%
#         mutate(rated = case_when(is.na(rating) ~ 0,
#                                  TRUE ~ 1)) %>%
#         mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
#                                  TRUE ~ 0)) %>%
#         mutate(owned = case_when())
#         nest(-username)
#         
# # load local
# active_games

```



```{r set up nested datasets, warning=F, message=F}

collections_outcomes = collections_info %>%
        filter(type == 'boardgame') %>%
        filter(!(is.na(yearpublished))) %>%
        select(username, yearpublished, date, game_id, name, rating, own, prevowned) %>%
        mutate(owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                 TRUE ~ 0)) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating, -prevowned, -name) %>%
        melt(id.vars = c("yearpublished", "username","date", "game_id")) %>%
        filter(value == 1) %>%
        rename(outcome_type = variable,
               outcome = value) %>%
        nest(-date, -username, -outcome_type) %>%
        arrange(username) %>%
        rename(user_data = data) %>%
        select(date, username, outcome_type, user_data)

# games
games = bind_rows(games_datasets$train,
                  games_datasets$test)

# split
year_split = 2019

# train
train_games = games %>%
        filter(yearpublished <= year_split)
# test
test_games = games %>%
        filter(yearpublished > year_split) 

# bake training
# create recipe 
prepped_recipe<- recipe(~ .,
                x = train_games %>% unnest()) %>%
        update_role(all_numeric(),
                    new_role = "predictor") %>%
        update_role(timestamp,
                    usersrated,
                    game_id,
                    name,
                    average,
                    baverage,
                    new_role = "id") %>%
        step_filter(!is.na(yearpublished)) %>%
        step_filter(
                cat_collectible_components !=1 &
                        cat_expansion_for_basegame != 1) %>% # remove specific categories that count expansions
  #      step_filter(yearpublished > 1900) %>%
        step_mutate(published_prior_1900 = case_when(yearpublished<1900 ~ 1,
                                                     TRUE ~ 0)) %>%
        step_mutate(yearpublished = case_when(yearpublished <= 1900 ~ 1900,
                                              TRUE ~ as.numeric(yearpublished))) %>% # truncate yearpublished
        # step_mutate(years_since_published = as.numeric(year(Sys.Date()))-yearpublished) %>%
        step_impute_median(avgweight,
                           minplayers,
                           maxplayers,
                           playingtime,
                           minage) %>% # medianimpute numeric predictors
        step_mutate(minplayers = case_when(minplayers < 1 ~ 1,
                                           minplayers > 10 ~ 10,
                                           TRUE ~ minplayers),
                    maxplayers = case_when(maxplayers < 1 ~ minplayers,
                                           maxplayers > 20 ~ 20,
                                           TRUE ~ maxplayers)) %>% # truncate player range
        step_mutate(time_per_player = playingtime/ maxplayers) %>% # make time per player variable
        step_mutate_at(starts_with("cat_"),
                       fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("mech_"),
                       fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("des_"),
                       fn = ~ replace_na(., 0)) %>%
       step_mutate_at(starts_with("art_"),
                       fn = ~ replace_na(., 0)) %>%
        step_mutate_at(starts_with("pub_"),
                       fn = ~ replace_na(., 0)) %>%
        # step_mutate_at(starts_with("own"),
        #                fn = ~ replace_na(., 0)) %>%
        # step_mutate_at(starts_with("owned"),
        #                fn = ~ replace_na(., 0)) %>%
        # step_mutate_at(starts_with("rated"),
        #                fn = ~ replace_na(., 0)) %>%
        step_mutate(number_mechanics = rowSums(across(starts_with("mech_"))),
                    number_categories = rowSums(across(starts_with("cat_")))) %>%
      #              number_artists = rowSums(across(starts_with("art_")))) %>%
        step_log(playingtime,
                 time_per_player,
                 offset = 1) %>%
        step_zv(all_numeric_predictors()) %>%
        step_nzv(all_predictors(),
              freq_cut = 150/1) %>%
        step_zv(all_predictors()) %>%
        step_corr(all_predictors(),
                          threshold = 0.95)

# penalized logistic regression
glmnet_class_mod<- 
        logistic_reg(penalty = tune::tune(),
                     mixture = 0.5) %>%
        set_engine("glmnet")

# specify grid for tuning
glmnet_grid <- tibble(penalty = 10^seq(-4, -0.5, 
                                       length.out = 30))

# specify regression metrics
reg_metrics<-metric_set(yardstick::rmse,
                        yardstick::rsq,
                        yardstick::mae,
                        yardstick::mape)

# specify regression metrics
class_metrics<-metric_set(yardstick::roc_auc,
                          yardstick::mn_log_loss)
        
# function for normalized recipe
norm_recipe_function = function(df, setting) {
        
        # change to factor if classification
        if (setting == 'classification') {df$outcome = as.factor(df$outcome)}
        else if (setting == 'regression') {df$outcome = df$outcome} 
        else {'select classification or regression'}
        
        norm_recipe = recipe_train <-
                recipe(outcome ~ ., data = df) %>%
                update_role(timestamp,
                            usersrated,
                            game_id,
                            name,
                            average,
                            baverage,
                            new_role = "id") %>%
                step_zv(all_predictors()) %>%
                step_corr(all_predictors(),
                          threshold = 0.95) %>%
                step_normalize(all_predictors())
        
}

# function for fitting workflow using a selected model and recipe
fit_workflow_function <- function(df, input_model, input_recipe, metrics) {
        
        # change to factor if classification
        if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
        else if (metrics == 'regression') {df$outcome = df$outcome} 
        else {'select classification or regression'}
        
        # fit model
        fit_wf <-
                workflow() %>%
                add_model(input_model) %>%
                add_recipe(input_recipe) %>%
                fit(df)
}

# function for tuning a workflow over folds
tune_workflow_function <- function(df, input_model, input_recipe, input_grid, metrics) {
        
        # change to factor if classification
        if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
        else if (metrics == 'regression') {df$outcome = df$outcome} 
        else {'select classification or regression'}
        
        # create folds
        set.seed(1999)
        train_folds = vfold_cv(df,
                               strata = outcome,
                               v = 5,
                               repeats = 1)
        
        # if regression then
        if (metrics == "regression") {
                fit_wf <-
                        workflow() %>%
                        add_model(input_model) %>%
                        add_recipe(input_recipe) %>%
                        tune_grid(train_folds,
                                  grid = input_grid,
                                  control = control_grid(save_pred = TRUE),
                                  metrics = reg_metrics)
        } else if (metrics == "classification") {
                fit_wf <-
                        workflow() %>%
                        add_model(input_model) %>%
                        add_recipe(input_recipe) %>%
                        tune_grid(train_folds,
                                  grid = input_grid,
                                  control = control_grid(save_pred = TRUE),
                                  metrics = class_metrics)
        } else {"select regression or classification"}
}

## for finalizing workflow
# function to finalize workflow using tune results
finalize_workflow_function<- function(df, input_model, input_recipe, tune_results, metrics) {
        
        # change to factor if classification
        if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
        else if (metrics == 'regression') {df$outcome = df$outcome} 
        else {'select classification or regression'}
        
        #fit workflow on train data
        fit_wf <-
                workflow() %>%
                add_model(input_model) %>%
                add_recipe(input_recipe)
        
        # finalize workflow
        final_wf <-
                fit_wf %>%
                finalize_workflow(tune_results) %>%
                fit(df)
}

```

Set up for models

```{r bake training and join with user data, warning=F, message=F}

# bake training set
baked_train_games = prepped_recipe %>%
        prep(train_games,  strings_as_factor =F) %>%
        bake(new_data = NULL) %>%
        mutate(type = "train") %>%
        nest(-type)

# train collections
collections_train_obj = collections_outcomes %>%
        unnest() %>%
        filter(yearpublished <= year_split) %>%
        nest(-date, -username, -outcome_type) %>%
        rename(user_data = data) %>%
        mutate(type = "train") %>%
        select(date, type, username, outcome_type, user_data) %>%
        left_join(., baked_train_games,
                  by = "type") %>%
        mutate(foo = map2(.x = user_data,
                          .y = data,
                          ~ .y %>% 
                                  left_join(., .x,
                                                    by = c("game_id",
                                                           "yearpublished")) %>%
                                  mutate(outcome = replace_na(outcome, 0)))) %>%
        select(date, type, username, outcome_type, user_data, foo) %>%
        rename(baked_data = foo)

```


```{r now train, warning=F, message=F}

# # register cores
# library(doParallel)
# cl = parallel::detectCores()-1
# registerDoParallel(cl)
# 
# # fit models to each collection, all at once
# collections_model_obj = collections_train_obj %>%
#                 filter(outcome_type == 'own') %>%
#                 mutate(glmnet_tune = map(baked_data,
#                                          ~ tune_workflow_function(df = .x,
#                                                                   input_model = glmnet_class_mod,
#                                                                   input_grid = glmnet_grid,
#                                                                   input_recipe = norm_recipe_function(.x, setting = 'classification'),
#                                                                   metrics = 'classification'))) %>%
#                 mutate(glmnet_best = map(glmnet_tune, ~ .x %>% show_best(n=1))) %>%
#                 mutate(glmnet_results = map2(.x = glmnet_tune,
#                                              .y = glmnet_best,
#                                              ~ .x %>% collect_predictions(parameters = .y) %>%
#                                                      arrange(.row))) %>%
#                 mutate(glmnet_fit = map2(.x = baked_data,
#                                          .y = glmnet_best,
#                                          ~ finalize_workflow_function(df = .x,
#                                                                       input_model = glmnet_class_mod,
#                                                                       tune_results = .y,
#                                                                       input_recipe = norm_recipe_function(.x, setting = 'classification'),
#                                                                       metrics = "classification")))
# 
# # save this beast so we dont have to run it again
# readr::write_rds(collections_model_obj,
#                  file = here::here("predict_user_collections/meta-analysis/files/", "collections_model_obj.Rds"))

# load
collections_model_obj = readr::read_rds(here::here("predict_user_collections/meta-analysis/files/", "collections_model_obj.Rds"))

```

resamples

test out getting coefs and preds for each user

```{r plot coefs, fig.height=10, fig.width=10}

source(here::here("functions/rename_func.R"))

sum_estimate = collections_model_obj %>%
        mutate(glmnet_coefs = map(glmnet_fit, ~ .x %>% extract_fit_parsnip() %>%
                                                  tidy())) %>%
        select(username, type, outcome_type, glmnet_coefs) %>% 
        unnest() %>%
        filter(term != '(Intercept)') %>%
        group_by(outcome_type, term) %>%
        summarize(mean_estimate = mean(estimate),
                  median_estimate = median(estimate))

top_40 = sum_estimate %>%
        arrange(desc(abs(mean_estimate))) %>%
        head(40) %>%
        pull(term)


collections_model_obj %>%
        mutate(glmnet_coefs = map(glmnet_fit, ~ .x %>% extract_fit_parsnip() %>%
                                                  tidy())) %>%
        select(username, type, outcome_type, glmnet_coefs) %>% 
        unnest() %>%
        filter(term != '(Intercept)') %>%
        filter(term %in% top_40) %>%
        mutate(term = rename_func(term)) %>%
      #  group_by(term) %>%
        # slice_max(order_by = abs(estimate),
        #           n=25,
        #           with_ties = F) %>%
        ggplot(., aes(x= reorder(term, estimate),
                      by = username,
                      y = estimate))+
        geom_jitter(alpha=0.6, width=0.1,
                    height = 0.001)+
        coord_flip()+
        #scale_color_grey(start = 0.2, end = 0.6)+
        scale_color_colorblind()+
        theme_phil()+
        theme(axis.text.y = element_text(size=rel(0.9)))+
        geom_hline(yintercept = 0,
                   linetype = 'dotted')+
        xlab("Feature")+
        ylab("Estimated Effect on Outcome")+
        theme_phil()

# top 20
top_10 = sum_estimate %>%
        arrange(desc(abs(mean_estimate))) %>%
        head(15) %>%
        pull(term)

collections_model_obj %>%
        mutate(glmnet_coefs = map(glmnet_fit, ~ .x %>% extract_fit_parsnip() %>%
                                                  tidy())) %>%
        select(username, type, outcome_type, glmnet_coefs) %>% 
        unnest() %>%
        filter(term != '(Intercept)') %>%
        filter(term %in% top_10) %>%
        select(-penalty) %>%
        mutate(term = rename_func(term)) %>%
        spread(term, estimate) %>%
        select(-username, -type, -outcome_type) %>%
        ggpairs()+
        theme_phil()+
        theme(panel.grid.major = element_blank(),
              panel.grid.minor = element_blank())

```

```{r games from resampling, warning=F, message=F, fig.height=10}

# function adding color to flextables
col_func<- function(x) {
  
  breaks<-seq(0, 1, .05)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

# examine oos preds
oos_raw= collections_model_obj %>%
                select(username, outcome_type, baked_data, glmnet_results) %>% 
                unnest() %>%
                arrange(.row) %>%
                select(username, yearpublished, outcome_type, game_id, name, outcome, .pred_1) %>%
                rename(pred = .pred_1,
                       actual = outcome) %>%
                pivot_wider(., names_from = c("outcome_type"),
                            values_from = c("pred", "actual")) %>%
                mutate_if(is.numeric, round, 2) %>%
                arrange(desc(pred_own)) %>%
                mutate(game_id = as.character(game_id),
                       yearpublished = as.character(yearpublished)) %>%
                select(username, yearpublished, game_id, name, everything()) 

# most recommended games
sum_raw = oos_raw %>%
        group_by(game_id, name, yearpublished) %>%
        summarize(mean_pred = mean(pred_own),
               sd_pred = sd(pred_own),
               users = n_distinct(username),
               in_collections = sum(actual_own),
               .groups = 'drop')
# table
sum_raw %>%
        arrange(desc(mean_pred)) %>%
        mutate_if(is.numeric, round, 3) %>%
                mutate_at(c("yearpublished", "game_id"),
                       ~ as.character(.)) %>%
        DT::datatable()

# get ranks
oos_preds_ranks = oos_raw %>%
        select(username, yearpublished, game_id, name, pred_own, actual_own) %>% 
        arrange(desc(pred_own)) %>%
        mutate(n_games = n_distinct(game_id),
               n_users = n_distinct(username)) %>%
        group_by(username, yearpublished) %>%
        ungroup() %>%
        arrange(desc(pred_own)) %>%
        group_by(username) %>%
        mutate(rank = row_number()) %>%
        select(n_games, n_users, yearpublished, game_id, name, everything()) %>%
        mutate(rank_tier = factor(case_when(rank <=25 ~ '1-25',
                                     rank >25 & rank<=50 ~ '26-50',
                                     rank >50 & rank<=100 ~ '50-100',
                                     rank >100 & rank<=200 ~ '101-200',
                                     rank >201 & rank<=500 ~ '201-500',
                                     TRUE ~ '500+'),
                                  levels = c("1-25",
                                             "26-50",
                                             "50-100",
                                             "101-200",
                                             "201-500",
                                             "500+")))
# flextable
oos_preds_ranks %>%
        ungroup() %>%
        mutate(n_users = n_distinct(username),
               n_games = n_distinct(game_id)) %>%
        group_by(game_id) %>%
        mutate(median_prob = mean(pred_own),
               median_rank = round(median(rank), 1),
               sd_rank = round(sd(rank),1),
               n_own = sum(actual_own),
               perc_own = n_own / n_users) %>%
        ungroup() %>%
        group_by(n_users, n_games, n_own, perc_own, median_rank, median_prob, sd_rank, yearpublished, game_id, name, rank_tier) %>%
        count() %>%
        ungroup() %>%
        mutate(perc = n/n_users) %>%
    #    group_by(rank_tier) %>%
        # pivot_wider(id_cols = c("outcome_type",
        #                         "yearpublished",
        #                         "game_id",
        #                         "name"),
        #             names_from = c("rank_tier"),
        #             values_from = c("n", "perc"))
        select(-n) %>%
        spread(rank_tier, perc) %>%
        mutate_if(is.numeric, replace_na, 0) %>%
        arrange(desc(perc_own)) %>%
        mutate_if(is.numeric, round, 2) %>%
        select(-n_users, -n_games, -sd_rank, -median_rank) %>%
        select(yearpublished, game_id, name, n_own, perc_own, median_prob, everything()) %>%
        mutate_at(c("yearpublished", "game_id"),
                       ~ as.character(.)) %>%
        head(500) %>%
        flextable() %>%
        flextable::autofit() %>%
        bg(., j=c("1-25",
                  "26-50",
                  "50-100",
                  "101-200",
                  "201-500",
                  "500+"),
           bg =col_func)

# oos_raw %>%
#         group_by(game_id, name, yearpublished) %>%
#         mutate(mean_pred = mean(pred_own),
#                sd_pred = sd(pred_own)) %>%
#         ungroup() %>%
#         filter(game_id %in% (sum_raw %>%
#                        arrange(desc(mean_pred)) %>%
#                        head(50) %>%
#                        pull(game_id))) %>%
#         mutate(actual_own = case_when(actual_own == 1 ~ 'yes',
#                                       TRUE ~ 'no')) %>%
#         ggplot(., aes(x=reorder(name, mean_pred),
#                       y=pred_own,
#                       color = actual_own,
#                       by= username))+
#         geom_jitter(width=0.1,
#                     height = 0.001)+
#         coord_flip()+
#         theme_phil()+
#         theme(axis.text.y = element_text(size=rel(0.8)))+
#         scale_color_manual(values = c("grey40", "deepskyblue1"))



```

calibration

```{r}

oos_raw %>%
        mutate(n_users = n_distinct(username)) %>%
        ungroup() %>%
        mutate(pred_prob = plyr::round_any(pred_own, .05)) %>%
        group_by(pred_prob) %>%
        summarize(n = n(),
                  own = sum(actual_own)) %>%
        mutate(actual_prob = own / n) %>%
        ggplot(., aes(x=pred_prob,
                      y=actual_prob))+
        geom_line()+
        geom_point(aes(size=n))+
        theme_phil()+
        geom_abline(intercept = 0,
                    slope = 1,
                    linetype = 'dashed',
                    col = 'grey60')+
        coord_cartesian(xlim = c(0, 0.9),
                       ylim = c(0, 0.9))+
        theme(legend.title = element_text())+
        guides(size = guide_legend(title = "Number of Predictions",
                                   title.position = 'top'))

oos_raw %>%
        group_by(yearpublished, username) %>%
        mutate()
        mutate(n_users = n_distinct(username)) %>%
        ungroup() %>%
        mutate(pred_prob = plyr::round_any(pred_own, .05)) %>%
        group_by(pred_prob) %>%
        summarize(n = n(),
                  own = sum(actual_own)) %>%
        mutate(actual_prob = own / n) %>%
        ggplot(., aes(x=pred_prob,
                      y=actual_prob))+
        geom_line()+
        geom_point(aes(size=n))+
        theme_phil()+
        geom_abline(intercept = 0,
                    slope = 1,
                    linetype = 'dashed',
                    col = 'grey60')+
        coord_cartesian(xlim = c(0, 0.9),
                       ylim = c(0, 0.9))+
        theme(legend.title = element_text())+
        guides(size = guide_legend(title = "Number of Predictions",
                                   title.position = 'top'))


        # mutate(n_users = n_distinct(username)) %>%
        # ungroup() %>%
        # group_by(game_id, name, n_users) %>%
        # summarize(median_prob = mean(pred_own),
        #        n_own = sum(actual_own),
        #        .groups = 'drop') %>%
        # mutate(perc_own = n_own / n_users) %>%
        # ggplot(., aes(x=median_prob,
        #               label = name,
        #               y=perc_own))+
        # geom_point(alpha=0.8)+
        # geom_text(check_overlap = T,
        #           hjust =0.2)+
        # theme_phil()+
        # ggpubr::stat_cor(label.x = 0.3, label.y = 0.4,
        #                  p.accuracy = 0.1,
        #                  col = 'blue')+
        # geom_smooth(formula = 'y~x',
        #             method = 'lm')+
        # geom_abline(intercept = 0,
        #             slope = 1)+
        # coord_cartesian(xlim = c(0,0.5),
        #                 ylim = c(0, 0.5))



```

predict test set

```{r}

# bake the test set
baked_test_games = prepped_recipe %>%
        prep(train_games,  strings_as_factor =F) %>%
        bake(new_data = test_games)

# test preds
test_preds = collections_model_obj %>%
        select(username, outcome_type, glmnet_fit) %>%
        #select(username, outcome_type, glmnet_fit, xgbTree_fit) %>%
        mutate(glmnet_preds = map(glmnet_fit,
                                  ~ .x %>%
                                          predict(baked_test_games, type = 'prob') %>%
                                          rename(glmnet = .pred_1) %>%
                                          select(glmnet) %>%
                                          mutate(.row = row_number())))%>%
        # mutate(xgbTree_preds = map(xgbTree_fit,
        #                            ~ .x %>%
        #                              predict(baked_test, type = 'prob') %>%
        #                              rename(xgbTree = .pred_1) %>%
        #                              select(xgbTree) %>%
        #                              mutate(.row = row_number()))) %>%
        select(username, outcome_type, glmnet_preds) %>%
        # select(username, outcome_type, glmnet_preds, xgbTree_preds) %>%
        unnest() %>%
        left_join(., test_games %>%
                          mutate(.row = row_number()),
                  by = ".row") %>%
        mutate(user_variable = paste(outcome_type, username, sep="_"))

# combine with collections
# train collections
collections_test_obj = collections_outcomes %>%
        unnest() %>%
        filter(yearpublished >= year_split) %>%
        nest(-date, -username, -outcome_type) %>%
        rename(user_data = data) %>%
        mutate(type = "test") %>%
        select(date, type, username, outcome_type, user_data) %>%
        left_join(., baked_test_games %>%
                          mutate(type = "test") %>%
                          nest(-type),
                  by = "type") %>%
        mutate(foo = map2(.x = user_data,
                          .y = data,
                          ~ .y %>% 
                                  left_join(., .x,
                                                    by = c("game_id",
                                                           "yearpublished")) %>%
                                  mutate(outcome = replace_na(outcome, 0)))) %>%
        select(date, type, username, outcome_type, user_data, foo) %>%
        rename(baked_data = foo)


```


```{r}

# calibration
test_preds %>%
        select(username, outcome_type, glmnet, own)
        mutate(n_users = n_distinct(username)) %>%
        ungroup() %>%
        mutate(pred_prob = plyr::round_any(pred_own, .05)) %>%
        group_by(pred_prob) %>%
        summarize(n = n(),
                  own = sum(actual_own)) %>%
        mutate(actual_prob = own / n) %>%
        ggplot(., aes(x=pred_prob,
                      y=actual_prob))+
        geom_line()+
        geom_point(aes(size=n))+
        theme_phil()+
        geom_abline(intercept = 0,
                    slope = 1,
                    linetype = 'dashed',
                    col = 'grey60')+
        coord_cartesian(xlim = c(0, 0.75),
                       ylim = c(0, 0.75))+
        theme(legend.title = element_text())+
        guides(size = guide_legend(title = "Number of Predictions",
                                   title.position = 'top'))



test_preds_ranks = test_preds %>%
        select(username, outcome_type, yearpublished, game_id, name, glmnet) %>% 
        arrange(desc(glmnet)) %>%
        group_by(username, outcome_type, yearpublished) %>%
        arrange(desc(glmnet)) %>%
        mutate(rank = row_number()) %>%
        mutate(rank_tier = factor(case_when(rank <=25 ~ '1-25',
                                     rank >25 & rank<=50 ~ '26-50',
                                     rank >50 & rank<=100 ~ '50-100',
                                     rank >100 & rank<=200 ~ '101-200',
                                     TRUE ~ '200+'),
                                  levels = c("1-25",
                                             "26-50",
                                             "50-100",
                                             "101-200",
                                             "200+")))


test_preds_ranks %>%
        group_by(game_id) %>%
        summarize(median_pred = median(glmnet)) %>%
        left_join(., baked_test_games) %>%
        ggplot(., aes(x=number_mechanics,
                      label = name,
               y= median_pred))+
        geom_jitter(alpha=0.6)+
        geom_text_repel(max.overlaps=50,
                        size = 4)+
        theme_phil()


# function adding color to flextables
col_func<- function(x) {
  
  breaks<-seq(0, 1, .05)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

test_preds_ranks %>%
        ungroup() %>%
        mutate(n_users = n_distinct(username)) %>%
        group_by(game_id) %>%
        mutate(avg_rank = round(median(rank), 1)) %>%
        ungroup() %>%
        group_by(n_users, avg_rank, outcome_type, yearpublished, game_id, name, rank_tier) %>%
        count() %>%
        ungroup() %>%
        mutate(perc = n/n_users) %>%
    #    group_by(rank_tier) %>%
        # pivot_wider(id_cols = c("outcome_type",
        #                         "yearpublished",
        #                         "game_id",
        #                         "name"),
        #             names_from = c("rank_tier"),
        #             values_from = c("n", "perc"))
        select(-n) %>%
        spread(rank_tier, perc) %>%
        mutate_if(is.numeric, replace_na, 0) %>%
        arrange(avg_rank) %>%
        mutate_if(is.numeric, round, 2) %>%
        select(-n_users) %>%
        select(outcome_type, yearpublished, game_id, name, avg_rank, everything()) %>%
        filter(yearpublished == 2021) %>%
        mutate_at(c("yearpublished", "game_id"),
                       ~ as.character(.)) %>%
        flextable() %>%
        flextable::autofit() %>%
        bg(., j=c("1-25",
                  "26-50",
                  "50-100",
                  "101-200",
                  "200+"),
           bg =col_func)


```


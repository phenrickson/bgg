---
title: "Meta Analysis of User Collections & Models"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 2
        number_sections: true
---
```{r load and set packages, echo=F, warning=F, message=F,  results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      error = F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

# source
source(here::here("scripts/load_packages.R"))
source(here::here("functions/theme_phil.R"))
rm(a)

# functions
source(here::here("functions/get_collection.R"))

# library
#library(webshot2)
library(magick)
library(flextable)
library(bggAnalytics)
library(tidymodels)
library(workflows)
library(rsample)

set_flextable_defaults(theme_fun = theme_booktabs,
                       font.color = "black",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

```{r get big query tables, warning=F, message=F}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query active games
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

# query active games
game_expansions<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.game_expansions')

# bgg_rankings<-bq_table_query(bq_bgg,
#                         query = 
#                         quiet = F)

# # set project and schema
# bq_bgg<- bq_dataset(project = PROJECT_ID,
#                                     dataset = 'bgg')

```

# Context {-}

I recently made a post in which I offered to train predictive models for user BoardGameGeek collections on r/boardgames. This amounted to training classification models for games that users own or have rated, training on games published before 2020 for must users and predicting games published from 2020 onwards. 

Link to post:
subbhttps://www.reddit.com/r/boardgames/comments/rtmq3o/post_your_bgg_username_and_ill_train_a_predictive/

This notebook is an analysis of the users who participated and what the models learned about the.

It is worth noting here that this is *not* a representative sample of either BGG or r/boardgames. Users selected into the sample based on viewing the reddit post over the weekend, which was January 1st, so if this sample represents any population it is the bored-at-home-and-checking-the-boardgame-subreddit-on-saturday-morning crowd. Nonetheless, we can still look at the data for these users and maybe make some cool visualizations.

# User Collections

I'll start by getting the full list of users for whom I have trained models - this includes some users from previous reddit posts, friends of mine, and some prominent reviewers.

```{r get user names from folder}

# get user list
users = list.files(here::here("predict_user_collections/user_reports")) %>%
        as_tibble() %>%
        filter(!grepl("(files)$", value)) %>% # filter out those that models didn't run for, which were ones with just the files
        rename(file = value) %>%
        mutate(user = gsub('.{10}$', '', file)) %>%
        mutate(year = str_sub(gsub(".html", "", file), -4, -1)) %>%
        mutate(user = case_when(user == 'The_Inquiry' ~ '_The_Inquiry_',
                                TRUE ~ user))

# how many analyses have i run?
n_users = users %>%
        mutate(date = Sys.Date()) %>%
        group_by(date) %>%
        summarize(users_analyzed = n_distinct(user))

n_users

```

As of `r n_users$date`, I have run analyses for `r n_users$users_analyzed` collections.

We'll now pull data for each of these collections into one large table.

```{r pull collections, warning=F, message=F, result='hide'}

# library(doParallel)
# library(parallel)
# 
# # get list of unique users
# get_users = unique(users$user)
# 
# registerDoParallel(detectCores()-1)
# 
# # loop in parallel
# user_collections = foreach(i = 1:length(get_users), 
#                            .packages = c('tidyverse',
#                                          'bggAnalytics'),
#                            .errorhandling = 'pass') %dopar% {
#                 
#                 foo = get_collection(get_users[i]) %>%
#                         nest(-username)
#                 
#                 foo
#                            }
# 
# # bind together
# user_collections_tbl= rbindlist(user_collections) %>% as_tibble()
# 
# # which names did we miss (due to whitespace?)
# missing_users = gsub("_",
#                      "%20",
#                      get_users[which(!(get_users %in% user_collections_tbl$username))])
# 
# #@ get these guys
# missing_users_collections = foreach(i = 1:length(missing_users), 
#                            .packages = c('tidyverse',
#                                          'bggAnalytics'),
#                            .errorhandling = 'pass') %dopar% {
#                 
#                 foo = get_collection(missing_users[i]) %>%
#                         nest(-username)
#                 
#                 foo
#                            }
# 
# # get into a tbl
# missing_users_collections_tbl = rbindlist(missing_users_collections) %>% as_tibble()
# 
# # bind together and get them together
# collections_table = bind_rows(user_collections_tbl,
#                               missing_users_collections_tbl)
# 
# # stop parallel
# registerDoSEQ()
# 
# # remove 
# rm(missing_users_collections,
#    missing_users_collections_tbl,
#    user_collections,
#    user_collections_tbl)

# # save locally
# readr::write_rds(collections_table,
#                                   file = here::here("predict_user_collections/meta-analysis/files", paste("collections_table_", Sys.Date(), ".Rdata", sep="")))

# load most recent
collections_files = list.files(here::here("predict_user_collections/meta-analysis/files"))
most_recent_table = collections_files[grepl("table", collections_files)]
most_recent_full_game_ids = collections_files[grepl("full_game_ids", collections_files)]
collections_table = readr::read_rds(here::here("predict_user_collections/meta-analysis/files", most_recent_table))
full_game_ids= readr::read_rds(here::here("predict_user_collections/meta-analysis/files", most_recent_full_game_ids))

```

We now have a table of all of these user's collections. We now need to get information from BGG about games, which we can use in our analysis. I'll also grab info on game expansions, as I'll want to omit those from a lot of this analysis

```{r get game info}

source(here::here("functions/get_bgg_data_from_github.R"))
source(here::here("functions/get_game_record.R"))

# get todays data from bgg
bgg_today<-get_bgg_data_from_github(Sys.Date())

# # get flattened file for these games _and any games that users might have that are not present here_
# bgg_game_ids = bgg_today %>%
#         select(game_id) %>%
#         pull(game_id) %>%
#         unique() 
# 
# # now we'll see if there are games users own, have rated, or have previously owned that aren't in the bgg data
# collection_game_ids = collections_table %>%
#         unnest(data) %>%
#         filter(!(game_id %in% unique(game_expansions$expansion_id))) %>%
#         pull(game_id) %>%
#         unique()
# 
# # how many games do people have that aren't in the bgg table?
# missing_game_ids = collection_game_ids[which(!(collection_game_ids %in% bgg_game_ids))]
# 
# # combine
# full_game_ids = c(bgg_game_ids,
#                   missing_game_ids)
# 
# # save game_ids
# readr::write_rds(full_game_ids, 
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("full_game_ids_", Sys.Date(), ".Rdata", sep="")))

# # split into model
# info = games_flattened %>%
#         select(timestamp,
#                type,
#                game_id,
#                type,
#                name,
#                yearpublished,
#                rank,
#                average,
#                baverage,
#                stddev,
#                usersrated,
#                avgweight,
#                minplayers,
#                maxplayers,
#                playingtime,
#                minplaytime,
#                maxplaytime,
#                minage,
#                numtrading,
#                numwanting,
#                numwishing,
#                numcomments)
# 
# categories = games_flattened %>%
#         select(game_id,
#                starts_with("cat")) %>%
#         melt(id.vars = c("game_id")) %>%
#         mutate(variable = gsub("^(cat_)", "", variable)) %>%
#         filter(value == 1) %>%
#         rename(category = variable)

```

We'll then get a full set of data on games from the daily BGG table as well as games that are in user collections.

```{r push all ids through API}

# use function to get records from bgg
# # takes about, 10 min?
# suppressMessages({
#         games_flattened = get_game_record(full_game_ids) %>%
#                 mutate(number_designers = rowSums(across(starts_with("des_"))))
# })

# # save both
# readr::write_rds(games_flattened,
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("games_flattened_", Sys.Date(), ".Rdata", sep="")))

# load from local
most_recent_flattened = collections_files[grepl("games_flattened", collections_files)]
games_flattened = readr::read_rds(here::here("predict_user_collections/meta-analysis/files",
                                             most_recent_flattened))

# readr::write_rds(flattened_names, 
#                  file = here::here("predict_user_collections/meta-analysis/files", paste("flattened_names_", Sys.Date(), ".Rdata", sep="")))

# # unite to one string varaible for storage
# games_united = games_flattened %>%
#         unite(string, sep = "_", remove = TRUE, na.rm = FALSE)
# 
# # get column names
# flattened_names = names(games_flattened)

# # get column names
# flattened_names = names(games_flattened)
# # separated
# games_separated = games_united %>%
#         separate(string, 
#                  into = flattened_names,
#                  convert = T,
#                  sep = "_",
#                  remove = T)

```

We can then join this up with our collection data as needed so we can get some basic features about games.

```{r combine}

collections_info = collections_table %>%
        unnest(data) %>%
        filter(game_id %in% full_game_ids) %>%
        left_join(., games_flattened %>%
                          select(timestamp,
                                 game_id,
                                 name,
                                 yearpublished,
                                 rank,
                                 average,
                                 baverage,
                                 stddev,
                                 usersrated,
                                 avgweight,
                                 minplayers,
                                 maxplayers,
                                 timestamp),
                  by = c("game_id"))

```

# Exploratory Analysis

## Collection Size

```{r plot owned, wanted, etc}


collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        group_by(variable) %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games)) %>%
        ggplot(., aes(x=games,
                      y=reorder(variable, median_games)))+
        stat_density_ridges(alpha=0.8,
                            quantile_lines = TRUE,
                            quantile_fun = median,
                            quantiles = 2) + 
        theme_phil()+
        xlab("number of games")+
        ylab("collection variable")

```

What was the distribution of games owned by the users (not counting expansions)?

```{r plot owned distribution}

temp = collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        filter(variable == 'own') %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games))

temp %>%
        ggplot(., aes(x=games))+
      #  geom_density(alpha=0.8)+
        geom_histogram(bins=100)+
        geom_vline(aes(xintercept = mean_games),
                   col = 'blue')+
        facet_wrap(variable~.,
                   ncol =1)+
        theme_phil()+
        annotate("text",
                 x = temp$median_games[1]*5,
                 y = 50,
                 color = 'blue',
                 label = paste('median games owned:', temp$median_games[1]))+
        xlab("number of games owned")+
        ylab("number of users")+
        annotate("text",
                 x = 0.9*temp$max_games[1],
                 y = 19,
                 color = "orange",
                 label = paste('most games owned:', temp$max_games[1]))+
        geom_curve(
                aes(x = 0.9*max_games, 
                    y = 15,
                    xend = max_games, 
                    yend = 5),
                data = temp,
                curvature = -0.2,
                color = 'orange',
                arrow = arrow(length = unit(0.03, "npc")))

rm(temp)

```

What about the distribution of games rated?

```{r plot owned}

temp = collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        filter(variable == 'rated') %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        mutate(mean_games = mean(games),
               median_games = median(games),
               max_games = max(games))

temp %>%
        ggplot(., aes(x=games))+
      #  geom_density(alpha=0.8)+
        geom_histogram(bins=100)+
        geom_vline(aes(xintercept = mean_games),
                   col = 'blue')+
        facet_wrap(variable~.,
                   ncol =1)+
        theme_phil()+
        annotate("text",
                 x = temp$median_games[1]*5,
                 y = 50,
                 color = 'blue',
                 label = paste('median games rated:', temp$median_games[1]))+
        xlab("number of games rated")+
        ylab("number of users")+
        annotate("text",
                 x = 0.9*temp$max_games[1],
                 y = 19,
                 color = "orange",
                 label = paste('most games rated:', temp$max_games[1]))+
        geom_curve(
                aes(x = 0.9*max_games, 
                    y = 15,
                    xend = max_games, 
                    yend = 5),
                data = temp,
                curvature = -0.2,
                color = 'orange',
                arrow = arrow(length = unit(0.03, "npc")))

```

How do these numbers usually compare (excluding users who did not rate at least one game)?

```{r owned vs rated}

collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        spread(variable, games) %>%
        filter(rated > 0) %>%
        mutate(diff = own - rated) %>%
        ggplot(., aes(x=own,
                      label = username,
                      y=rated))+
        geom_point(alpha=0.75)+
        # geom_text_repel(check_overlap = T,
        #           size = 3)+
        theme_phil()+
        geom_abline(intercept = 0,
                    slope = 1,
                    linetype = 'dotted')+
        annotate("label",
                 x = 150,
                 y = 1200,
                 label = "rate more than own")+
        annotate("label",
                 x = 850,
                 y = 150,
                 label = "own more than rate")

collections_info %>%
        filter(type == 'boardgame') %>%
        select(username, date, game_id, rating, own, prevowned) %>%
        mutate(rated = case_when(is.na(rating) ~ 0,
                                 TRUE ~ 1)) %>%
        select(-rating) %>%
        melt(id.vars = c("username", "date", "game_id")) %>%
        group_by(username, date, variable) %>%
        summarize(games = sum(value),
                  .groups = 'drop') %>%
        spread(variable, games) %>%
        filter(rated > 0) %>%
        mutate(diff = own - rated) %>%
        ggplot(., aes(x=diff))+
        geom_density(fill = 'gray60',
                     color = 'grey60',
                     alpha = 0.9)+
      #  geom_histogram(bins = 100)+
        theme_phil()+
        xlab("Games Owned - Games Rated")
        
```

How do the users compare in their ratings to the average ratings on BoardGameGeek?

```{r user ratings vs average, fig.height=20, fig.width=10}

set.seed(1999)
samp_ratings = collections_info %>%
        filter(!(is.na(rating))) %>%
        filter(type == 'boardgame') %>% 
        group_by(game_id) %>%
        mutate(sample_mean = mean(rating),
               sample_median = median(rating),
               sd_ratings = sd(rating),
               sample_ratings = n()) %>%
        filter(sample_ratings > 14) %>%
        ungroup() %>%
        arrange(desc(sample_mean)) 

sum_ratings= collections_info %>%
        filter(!(is.na(rating))) %>%
        filter(type == 'boardgame') %>% 
        group_by(game_id, name) %>%
        summarize(sample_mean = mean(rating),
                  sd_ratings = sd(rating),
                  sample_median = median(rating),
                  sample_ratings = n(),
                  .groups = 'drop') %>%
        filter(sample_ratings > 9) %>%
        arrange(desc(sample_mean))
        
# top 
samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                       head(100) %>%
                       pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sample_mean),
                      x=rating))+
        stat_density_ridges(alpha=0.8,
                            color = 'white',
                            quantile_lines = TRUE,
                            quantile_fun = mean,
                            quantiles = 2)+
        theme_phil()+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))
```

Lowest

```{r lowest rated, fig.height=20, fig.width=10}

# bottom
samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                       tail(100) %>%
                       pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sample_mean),
                      x=rating))+
        stat_density_ridges(alpha=0.8,
                            color = 'white',
                            quantile_lines = TRUE,
                            quantile_fun = mean,
                            quantiles = 2)+
        theme_phil()+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))

```

Most polarizing

```{r lowest rated, fig.height=20, fig.width=10}


samp_ratings %>%
        filter(game_id %in% (sum_ratings %>% 
                                     arrange(desc(sd_ratings)) %>%
                                     head(100) %>%
                                     pull(game_id))) %>%
        ggplot(., aes(y=reorder(name, sd_ratings),
                      x=rating))+
        stat_density_ridges(alpha=0.8,
                            color = 'white',
                            quantile_lines = TRUE,
                            quantile_fun = mean,
                            quantiles = 2)+
        theme_phil()+
        theme(panel.grid.minor = element_blank(),
              panel.grid.major = element_blank())+
        coord_cartesian(xlim = c(0, 11))+
        theme(axis.text.y = element_text(size=12))+
        ggtitle("Which Games are the Most Polarizing?",
                subtitle = str_wrap("Displaying distributions of ratings for games with highest variance in sample of user collections. Filtering to games with at least 15 ratings.", 125))


```

Games most frequently owned

```{r games owned, fig.height=8, fig.width=10}

collections_info %>%
        group_by(game_id, name) %>%
        count() %>%
        ungroup() %>%
        slice_max(order_by = n,
                  n = 100) %>%
        ggplot(., aes(x=reorder(name,n),
                      
                      y=n))+
        geom_col()+
        theme_phil()+
        coord_flip()+
        theme(panel.grid.major = element_blank())

```

What are the most frequent combinations of games in collections?

```{r make polot, fig.height=10, fig.width=10}
spread_games = games_flattened %>%
        mutate(game_id = as.integer(game_id)) %>%
        filter(!(game_id %in% (game_expansions$expansion_id))) %>%
        select(yearpublished, game_id, name) %>%
        left_join(.,
                  collections_info %>%
                          mutate(game_id = as.integer(game_id)) %>%
                          select(username, game_id, own, name) %>%
                          filter(own==1) %>%
                          mutate(username = paste("own", username, sep="_")) %>%
                          pivot_wider(id_cols=c("game_id", "name"),
                                      names_from = c("username"),
                                      values_from = c("own")) %>%
                          mutate_if(is.numeric, replace_na, 0),
                  by = c("game_id", "name")
                  ) %>%
        mutate_if(is.numeric, replace_na, 0)
        
```

```{r upset plot, fig.height=20, fig.width=10}

spread_games %>%
        select(-yearpublished, -game_id, -name)
        mutate_if(is.numeric, as.integer) %>%
        as.data.frame() %>%
        upset(.,
              nsets = 25,
              show.numbers = F,
              text.scale = 3,
              point.size = 4,
              line.size=1.5,
              #    nintersects = 50,
              mb.ratio = c(.4, .6),
              mainbar.y.label = "# of Games Played \n by Combination of User",
              sets.x.label = "# of Games by User",
              order.by = "freq")

```


collections_info %>%
        filter(type == 'boardgame') %>%
        group_by(game_id) %>%
        mutate(users_own = sum(own)) %>%
        arrange(desc(users_own))
        ungroup() %>%
        select(username, date, game_id, name, own, users_own)
        select(-name, -users_own, -date) %>%
        spread(game_id, own) %>%
        mutate_if(is.numeric, replace_na, 0) %>%
        filter(`13` == 1)

# flip tp upset
spread_names %>%
        select(-username) %>%
        mutate_if(is.numeric, as.integer) %>%
        as.data.frame() %>%
        upset(.,
              nsets = 25,
              show.numbers = F,
              text.scale = 3,
              point.size = 4,
              line.size=1.5)
              #    nintersects = 50,
              mb.ratio = c(.4, .6),
              mainbar.y.label = "# of Games Played \n by Combination of User",
              sets.x.label = "# of Games by User",
              order.by = "freq")


    

```


```{r user average vs bgg average, fig.height=8, fig.width=10, warning=F, message=F}

set.seed(1999)
library(plotly)

#ggplotly(
collections_info %>%
        filter(!(is.na(rating))) %>%
        group_by(game_id, name, average, usersrated) %>%
        summarize(sample_average = mean(rating),
                  sample_ratings = n(),
                  .groups = 'drop') %>%
        mutate(diff = sample_average - average) %>%
        filter(sample_ratings > 5) %>%
        ggplot(., aes(x=sample_average,
              #        size = sample_ratings,
                  color = diff,
                      label = name,
                      y=average))+
        geom_point()+
        geom_text_repel(max.overlaps=25,
                        size = 3)+
        theme_phil()+
        geom_abline(slope=1,
                    intercept = 0,
                    linetype = 'dotted',
                    col = 'grey60')+
     #   geom_smooth(show.legend=F)+
        theme(legend.title = element_text())+
        guides(color = guide_colorbar(title.position = 'top',
                                      barheight = 0.5,
                                      barwidth=15,
                                    title = 'Sample Average - BGG Average'),
               size = "none")+
        scale_color_gradient(low = "red",
                             high = "deepskyblue1",
                             oob = scales::squish)
        # scale_color_gradient2_tableau(limits = c(-4,
        #                                          4),
        #                               oob = scales::squish)

# size = guide_legend(title.position = 'top',
#                                    title = 'Ratings in Sample'),
#                

```

---
title: "Methodology for Comparing and Recommending Board Games"
author: "Phil Henrickson"
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 2
        number_sections: true
---

```{r global settings, echo=F, warning=F, message=F, results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      error=F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

source(here::here("scripts/load_packages.R"))
source(here::here("functions/theme_phil.R"))

```


```{r load in necessary pieces, warning=F, message=F}

# load function
source(here::here("functions/get_game_record.R"))
source(here::here("functions/baverage_func.R"))
source(here::here("functions/average_func.R"))
source(here::here("functions/avgweight_func.R"))

# load active files
unsupervised_obj = 
        readr::read_rds(here::here("active", "unsupervised_obj.Rdata"))

unsupervised_neighbors = 
        readr::read_rds(here::here("active", "unsupervised_neighbors.Rdata")) 

recipe_prep = 
        readr::read_rds(here::here("active", "unsupervised_recipe_prep.Rdata"))

# games_flattened = 
#         readr::read_rds(here::here("active", "games_flattened.Rdata"))  %>%
#         select(game_id,
#                name,
#                yearpublished,
#                average,
#                baverage,
#                avgweight,
#                playingtime,
#                usersrated,
#                minplayers,
#                maxplayers)

```

```{r big query for active games, warning=F, message=F}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query table
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

# create caption for plots
my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))
```


# Background

This report summarizes and explains my methodology for examining a boardgame and identifying **its most comparable games using data from boardgamegeek.com**. To summarize, I use a dimension reduction method (PCA) to learn the main points of variation in data about games from boardgamegeek. I then compute the distance Manhattan between all games based on their values on the first ten principal components. Games that are close to each other are said to be *neighbors*.

To see the results of this analysis in action, go to... for an interactive report allowing the end user to select a game and see its neighbors in an interactive fashion.

# Motivation

'Oh, you haven't played a lot of games but you like Catan? You should check out Concordia.'

'You like Betrayal at the House on the Hill? You should check out the other games in that series, like Betrayal at Baldur's Gate or Betrayal Legacy. Or, you might enjoy something like Mansions of Madness.'

'Your favorite game is High Frontier 4 All? Uh, would you look at that, I'm late for a dental appointment.'

If you've been in the hobby of board games for a while, you probably have a mental mapping of games that you use to make recommendations to friends, family, and colleagues. If someone mentions that they're looking for a new game, you generally ask for some examples of games they like. Based on what they tell you, you start thinking about the various features of games (complexity, playing time, theme, price), and then try to identify something that will be similar to what they told you.

You are, in other words, a recommendation engine. And probably a pretty darn good one. You receive an input, push it through your mental map (a function), and return an output. Over time, you've fine tuned your function and have gotten pretty good at ensuring that output is pretty useful.

But you do have some limits. If someone mentions a game you've never heard of before, it will be difficult to place it on your mental map. You also, presumably, have other things going on in your life (showering, eating, cleaning the cat litter) that prevent you from being on demand to to recommend new games to anyone who asks. And as good as you are, you might also not recognize some patterns that exist between games - as sharp as your mental mapping might be, it's hard to take into account all of the information that exists and recommend the best possible fit.

Fortunately for us, computers have nothing better to do and can process lots of information whenever we want (for now at least; see The Matrix). Rather than relying on our mental map, we can try to use data collected about board games in order to recreate what we are currently doing manually.

# How do we find similar games?

Finding similar games amounts to measuring the distance between games and identifying the ones that are closest to each other. But what dimensions should we be using to measure games? And how do we define the distance between them? 

Let's start with a simple, unidimensional example. Let's say we have a universe of 26 games, each represented by a letter in the alphabet. 

[show alphabet line]

In this wildly simplified example we have one discrete dimension where our only unit of measurement is the number of spaces between letters. (We'll assume that the dimensions ends at A and Z; it doesn't wrap around. There's a mathematical term for this, but I won't pretend to be learned in speaking like a mathematician or game theorist when it comes to these things, I was a humanities major dammit.)

In this case, Game X's nearest neighbors are games W and Y, as they're both one space away. We can find the distance between every game in this way:

[This is what the matrix looks like]

To find similar games, we just find the ones that minimize the distance between them. If you like game X, we'll recommend W and Y. We might also toss V and Z into the mix to see what you think of those. But we're not going to recommend you game A, at least not to start, as it is the furthest away. Our method for finding similar units amounts to this:

1. Identify dimension (place in the alphabet) on which to place units
2. Place all units on dimension
3. Measure distance between units
4. For a given unit, select its nearest units

There is an additional step we'd like to get to, gaining feedback based on the selection of units, but for now we'll keep it simple and be satisfied if we can identify neighbors.

## Recommending Games in One Dimension

Let's stay in one dimension, but switch over to data about board games. What dimension do we typically use to group and evaluate games? My mind goes immediately to the idea of **complexity**: how complicated is it to learn, how long will it take to play, how many different actions are there, etc. 

All of us probably bin our collection on this dimension already: we all probably have an area in our collection for 'games we would play with non gamers' as well as another area for 'games we probably can only play with our brother who lives across the country and has the same appetite as us for learning and playing really complex games'. We all do that, right?

At any rate, boardgamegeek has a complexity measure we can use to proxy for complexity and place all games on one dimensions. Here is what that looks like:

[Jitter plot with games]

Now, with this in mind, we can measure the distance between any game by simply subtracting their distances from each other. We'll follow the same process as above, but now computing it based on some real data.

1. Identify dimension (complexity) on which to place games
2. Place games on dimension
3. Measure distance between games
4. For a given game, return its nearest neighbors

This means, if you like Inis, you'll like... 

If you like War of the Ring, you'll like...

Hmm. So based on what we're seeing right now, we might not be to happy with what we're getting. We've followed the steps we outlined, it sounded well and good, but we've hit a snag at the all important next step:

5. Examine nearest neighbors and evaluate the results.

In other words, we're looking at the output and realizing that it isn't quite mapping to what we want. How are we determining that? Our gut, mostly. Our theoretical concept in our heads of what it means for two games to be similar. If we think about our mental map, we typically think about board concepts like complexity, theme, mechanics.

And right now, we're missing things that might we expect to matter. Is Inis' most similar game really...?

Well, presumably, in order to get closer to our theoretical concept, we need to introduce some more data points about games. There are some other things we should think about, like the theme and setting of the game, what type of mechanics it uses, its player count.

## Recommending Games in Two Dimensions



How thematic is the game?
How complex is the game?






### Manhattan


### Euclidean


### Recommending Games in N Dimensions


## Dimension Reduction



## Examining PCA Variable Loadings

What explains a game's score on each principal component?

To gain a better understanding of these principal components, we can look at the loadings for the variables in the dataset. These are the the contributions of each variable to the ten components used in computing the distance between games. Large loadings (either positive or negative) for a variable indicate that there is a strong relationship between that variable and the component.

For instance, on the first principal component (PC1), **time per player**, **average weight**, and **playing time** have the highest positive loadings, while **party game** and **max players** have negative loadings. This indicates that this component seems to map to a game's complexity - longer, more complex games will have high positive scores on this component while simpler, shorter, party games with lots of players will have low scores. 

```{r examine variable loadings, warning=F, message=F, fig.height=12, fig.width=10}

unsupervised_obj_components %>% 
        select(dataset, pca_component)
  filter(component == 'PC1' | 
           component == 'PC2' | 
           component == 'PC3' | component == 'PC4' |
           component == 'PC5' | component == 'PC6' |
           component == 'PC7' | component == 'PC8' |
           component == 'PC9' | component == 'PC10') %>%
  mutate(component = factor(component,
                            levels = c("PC1",
                                       "PC2",
                                       "PC3",
                                       "PC4",
                                       "PC5",
                                       "PC6",
                                       "PC7",
                                       "PC8",
                                       "PC9",
                                       "PC10"))) %>%
  group_by(dataset, component) %>%
  slice_max(., order_by = abs(value),
            n = 15) %>%
  mutate(terms = rename_func(terms)) %>%
  ggplot(., aes(x=value,
                fill = value,
                y = reorder_within(terms, by =value, within = component)))+
  geom_col()+
  scale_y_reordered()+
  facet_wrap(. ~ component,
             ncol =2,
             scales = "free_y")+
  theme_phil()+
  ylab("feature")+
  xlab("contribution")+
  guides(fill = guide_colorbar(barwidth = 10,
                               barheight=0.5))+
  scale_fill_viridis(option="magma",
                                      begin = 0.2,
                                      end = 0.8)+
  ggtitle("What contributes to each principal component?")+
  guides(fill = "none")
        
```


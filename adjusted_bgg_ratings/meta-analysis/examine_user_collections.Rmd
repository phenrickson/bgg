---
title: "Meta Analysis of User Collections & Models"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 2
        number_sections: true
---
```{r load and set packages, echo=F, warning=F, message=F,  results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      error = F,
                      dev="png",
                      fig.width = 10,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

# source
source(here::here("scripts/load_packages.R"))
source(here::here("functions/theme_phil.R"))

# functions
source(here::here("functions/get_collection.R"))

# library
#library(webshot2)
library(magick)
library(flextable)
library(bggAnalytics)
library(tidymodels)
library(workflows)
library(rsample)

set_flextable_defaults(theme_fun = theme_booktabs,
                       font.color = "black",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```


# Context {-}

I recently made a post in which I offered to train predictive models for user BoardGameGeek collections on r/boardgames. This amounted to training classification models for games that users own or have rated, training on games published before 2020 for must users and predicting games published from 2020 onwards. 

Link to post:
subbhttps://www.reddit.com/r/boardgames/comments/rtmq3o/post_your_bgg_username_and_ill_train_a_predictive/

This notebook is an analysis of the users who participated and what the models learned about the.

It is worth noting here that this is *not* a representative sample of either BGG or r/boardgames. Users selected into the sample based on viewing the reddit post over the weekend, which was January 1st, so if this sample represents any population it is the bored-at-home-and-checking-the-boardgame-subreddit-on-saturday-morning crowd. Nonetheless, we can still look at the data for these users and maybe make some cool visualizations.

# User Collections

I'll start by getting the full list of users for whom I have trained models - this includes some users from previous reddit posts, friends of mine, and some prominent reviewers.

```{r get user names from folder}

# get user list
users = list.files(here::here("predict_user_collections/user_reports")) %>%
        as_tibble() %>%
        filter(!grepl("(files)$", value)) %>% # filter out those that models didn't run for, which were ones with just the files
        rename(file = value) %>%
        mutate(user = gsub('.{10}$', '', file)) %>%
        mutate(year = str_sub(gsub(".html", "", file), -4, -1)) %>%
        mutate(user = case_when(user == 'The_Inquiry' ~ '_The_Inquiry_',
                                TRUE ~ user))

# how many analyses have i run?
n_users = users %>%
        mutate(date = Sys.Date()) %>%
        group_by(date) %>%
        summarize(users_analyzed = n_distinct(user))

n_users
```
As of `r n_users$date`, I have run analyses for `r n_users$users_analyzed` collections.

We'll now pull data for each of these collections into one large table.

```{r pull collections, warning=F, message=F, result='hide'}

library(doParallel)
library(parallel)

# get list of unique users
get_users = unique(users$user)

registerDoParallel(detectCores()-1)

# loop in parallel
user_collections = foreach(i = 1:length(get_users), 
                           .packages = c('tidyverse',
                                         'bggAnalytics'),
                           .errorhandling = 'pass') %dopar% {
                
                foo = get_collection(get_users[i]) %>%
                        nest(-username)
                
                foo
                           }

# bind together
user_collections_tbl= rbindlist(user_collections) %>% as_tibble()

# which names did we miss (due to whitespace?)
missing_users = gsub("_",
                     "%20",
                     get_users[which(!(get_users %in% user_collections_tbl$username))])

#@ get these guys
missing_users_collections = foreach(i = 1:length(missing_users), 
                           .packages = c('tidyverse',
                                         'bggAnalytics'),
                           .errorhandling = 'pass') %dopar% {
                
                foo = get_collection(missing_users[i]) %>%
                        nest(-username)
                
                foo
                           }

# get into a tbl
missing_users_collections_tbl = rbindlist(missing_users_collections) %>% as_tibble()

# bind together and get them together
collections_table = bind_rows(user_collections_tbl,
                              missing_users_collections_tbl)

# remove 
rm(missing_users_collections,
   missing_users_collections_tbl,
   user_collections,
   user_collections_tbl)

```

We now have a table of all of these user's collections. We now need to get information from BGG about games, which we can use in our analysis.

```{r get game info}

source()
active_games = 


```

